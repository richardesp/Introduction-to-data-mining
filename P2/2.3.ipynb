{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Disable warning of Ripper implementation\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn import tree, svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn_evaluation import plot\n",
    "import seaborn as sns\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = arff.loadarff('ionosphere.arff')\n",
    "df_iono = pd.DataFrame(data[0])\n",
    "\n",
    "data = arff.loadarff('diabetes.arff')\n",
    "df_diabe = pd.DataFrame(data[0])\n",
    "\n",
    "data = arff.loadarff('vehicle.arff')\n",
    "df_Vehicle = pd.DataFrame(data[0])\n",
    "\n",
    "data = arff.loadarff('vowel.arff')\n",
    "df_vowel = pd.DataFrame(data[0])\n",
    "\n",
    "data = arff.loadarff('iris.arff')\n",
    "df_iris = pd.DataFrame(data[0])\n",
    "\n",
    "data = arff.loadarff('letter.arff')\n",
    "df_letter = pd.DataFrame(data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Changing the last categorical class value into a numerical value\n",
    "df_iono['class'] = pd.factorize(df_iono['class'])[0]\n",
    "\n",
    "# Changing the last categorical class value into a numerical value\n",
    "df_diabe['class'] = pd.factorize(df_diabe['class'])[0]\n",
    "\n",
    "# Changing the last categorical class value into a numerical value\n",
    "df_Vehicle['Class'] = pd.factorize(df_Vehicle['Class'])[0]\n",
    "\n",
    "# Changing the last categorical class value into a numerical value\n",
    "df_vowel['Class'] = pd.factorize(df_vowel['Class'])[0]\n",
    "\n",
    "# Changing the last categorical class value into a numerical value\n",
    "df_iris['class'] = pd.factorize(df_iris['class'])[0]\n",
    "\n",
    "# Changing the last categorical class value into a numerical value\n",
    "df_letter['class'] = pd.factorize(df_letter['class'])[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "trainIono, testIono = train_test_split(df_iono, test_size=.25)\n",
    "X_trainIono = trainIono.drop('class', axis=1)\n",
    "y_trainIono = trainIono['class']\n",
    "X_testIono = testIono.drop('class', axis=1)\n",
    "y_testIono = testIono['class']\n",
    "\n",
    "trainDiabe, testDiabe = train_test_split(df_diabe, test_size=.25)\n",
    "X_trainDiabe = trainDiabe.drop('class', axis=1)\n",
    "y_trainDiabe = trainDiabe['class']\n",
    "X_testDiabe = testDiabe.drop('class', axis=1)\n",
    "y_testDiabe = testDiabe['class']\n",
    "\n",
    "trainVehicle, testVehicle = train_test_split(df_Vehicle, test_size=.25)\n",
    "X_trainVehicle = trainVehicle.drop('Class', axis=1)\n",
    "y_trainVehicle = trainVehicle['Class']\n",
    "X_testVehicle = testVehicle.drop('Class', axis=1)\n",
    "y_testVehicle = testVehicle['Class']\n",
    "\n",
    "trainVowel, testVowel = train_test_split(df_vowel, test_size=.25)\n",
    "X_trainVowel = trainVowel.drop('Class', axis=1)\n",
    "y_trainVowel = trainVowel['Class']\n",
    "X_testVowel = testVowel.drop('Class', axis=1)\n",
    "y_testVowel = testVowel['Class']\n",
    "\n",
    "trainIris, testIris = train_test_split(df_iris, test_size=.25)\n",
    "X_trainIris = trainIris.drop('class', axis=1)\n",
    "y_trainIris = trainIris['class']\n",
    "X_testIris = testIris.drop('class', axis=1)\n",
    "y_testIris = testIris['class']\n",
    "\n",
    "trainLetter, testLetter = train_test_split(df_letter, test_size=.25)\n",
    "X_trainLetter = trainLetter.drop('class', axis=1)\n",
    "y_trainLetter = trainLetter['class']\n",
    "X_testLetter = testLetter.drop('class', axis=1)\n",
    "y_testLetter = testLetter['class']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('Ionosphere', X_trainIono, y_trainIono, X_testIono, y_testIono),\n",
    "    ('Diabetes', X_trainDiabe, y_trainDiabe,X_testDiabe, y_testDiabe),\n",
    "    ('Vehicle', X_trainVehicle, y_trainVehicle, X_testVehicle, y_testVehicle),\n",
    "    ('Vowel', X_trainVowel, y_trainVowel, X_testVowel, y_testVowel),\n",
    "    ('Iris', X_trainIris, y_trainIris, X_testIris, y_testIris),\n",
    "    ('Letter', X_trainLetter, y_trainLetter, X_testLetter, y_testLetter)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison without using GridSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "clf_svm = svm.SVC()\n",
    "clf_BaggingTree = BaggingClassifier(estimator=clf_tree)\n",
    "clf_AdaBoostSAMMETree = AdaBoostClassifier(estimator=clf_tree,algorithm='SAMME')\n",
    "clf_AdaBoostSAMMERTree = AdaBoostClassifier(estimator=clf_tree,algorithm='SAMME.R')\n",
    "clf_BaggingSVM = BaggingClassifier(estimator=clf_svm)\n",
    "clf_AdaBoostSAMMESVM = AdaBoostClassifier(estimator=clf_svm,algorithm='SAMME')\n",
    "clf_AdaBoostSAMMERSVM = AdaBoostClassifier(estimator=clf_svm,algorithm='SAMME.R')\n",
    "clf_GradBoost = GradientBoostingClassifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9272079772079772 +- 0.03655976731195557\n",
      "Tiempo medio en ejecutarse el método (train): 0.006222295761108399 +- 0.006222295761108399s\n",
      "Tiempo medio en ejecutarse el método (score): 0.002826356887817383 +- 0.002826356887817383s\n",
      "Tiempo en ejecutarse la búsqueda 3.044736623764038s, (0.0507456103960673 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.7551119177253478 +- 0.06743984851311845\n",
      "Tiempo medio en ejecutarse el método (train): 0.014174675941467286 +- 0.014174675941467286s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0041184663772583004 +- 0.0041184663772583004s\n",
      "Tiempo en ejecutarse la búsqueda 1.0964512825012207s, (0.01827418804168701 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8232638888888889 +- 0.03830704516341843\n",
      "Tiempo medio en ejecutarse el método (train): 0.01577138900756836 +- 0.01577138900756836s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0033438682556152345 +- 0.0033438682556152345s\n",
      "Tiempo en ejecutarse la búsqueda 0.05295896530151367s, (0.0008826494216918945 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9460540540540539 +- 0.01896026370354104\n",
      "Tiempo medio en ejecutarse el método (train): 0.008792424201965332 +- 0.008792424201965332s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0025958776473999023 +- 0.0025958776473999023s\n",
      "Tiempo en ejecutarse la búsqueda 0.033531904220581055s, (0.0005588650703430176 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9818181818181818 +- 0.036363636363636376\n",
      "Tiempo medio en ejecutarse el método (train): 0.004335379600524903 +- 0.004335379600524903s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0021129846572875977 +- 0.0021129846572875977s\n",
      "Tiempo en ejecutarse la búsqueda 0.020422697067260742s, (0.0003403782844543457 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9206000000000001 +- 0.005683895377878343\n",
      "Tiempo medio en ejecutarse el método (train): 2.900859498977661 +- 2.900859498977661s\n",
      "Tiempo medio en ejecutarse el método (score): 1.58134868144989 +- 1.58134868144989s\n",
      "Tiempo en ejecutarse la búsqueda 4.979156255722046s, (0.08298593759536743 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &    TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.006222 &   0.002826 &  3.044737 &  0.927208 \\\\\n",
      "1 &    Diabetes &   0.014175 &   0.004118 &  1.096451 &  0.755112 \\\\\n",
      "2 &     Vehicle &   0.015771 &   0.003344 &  0.052959 &  0.823264 \\\\\n",
      "3 &       Vowel &   0.008792 &   0.002596 &  0.033532 &  0.946054 \\\\\n",
      "4 &        Iris &   0.004335 &   0.002113 &  0.020423 &  0.981818 \\\\\n",
      "5 &      Letter &   2.900859 &   1.581349 &  4.979156 &  0.920600 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreSVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_svm,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreSVM.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreSVM)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8703703703703702 +- 0.04587248486639492\n",
      "Tiempo medio en ejecutarse el método (train): 0.013461613655090332 +- 0.013461613655090332s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0026299476623535155 +- 0.0026299476623535155s\n",
      "Tiempo en ejecutarse la búsqueda 0.13106179237365723s, (0.0021843632062276204 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.6803992740471869 +- 0.0436210209538901\n",
      "Tiempo medio en ejecutarse el método (train): 0.007199478149414062 +- 0.007199478149414062s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0022942066192626954 +- 0.0022942066192626954s\n",
      "Tiempo en ejecutarse la búsqueda 0.058751821517944336s, (0.0009791970252990723 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.927405753968254 +- 0.016273716056452166\n",
      "Tiempo medio en ejecutarse el método (train): 0.00684504508972168 +- 0.00684504508972168s\n",
      "Tiempo medio en ejecutarse el método (score): 0.002187180519104004 +- 0.002187180519104004s\n",
      "Tiempo en ejecutarse la búsqueda 0.028808116912841797s, (0.0004801352818806966 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9757117117117119 +- 0.01177303419105685\n",
      "Tiempo medio en ejecutarse el método (train): 0.008149266242980957 +- 0.008149266242980957s\n",
      "Tiempo medio en ejecutarse el método (score): 0.002184605598449707 +- 0.002184605598449707s\n",
      "Tiempo en ejecutarse la búsqueda 0.028464078903198242s, (0.00047440131505330403 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9545454545454545 +- 0.06098367211363062\n",
      "Tiempo medio en ejecutarse el método (train): 0.003684258460998535 +- 0.003684258460998535s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0018049001693725586 +- 0.0018049001693725586s\n",
      "Tiempo en ejecutarse la búsqueda 0.020107030868530273s, (0.0003351171811421712 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8622 +- 0.009615034523541182\n",
      "Tiempo medio en ejecutarse el método (train): 0.11896159648895263 +- 0.11896159648895263s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0031336545944213867 +- 0.0031336545944213867s\n",
      "Tiempo en ejecutarse la búsqueda 0.2857940196990967s, (0.0047632336616516115 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &    TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.013462 &   0.002630 &  0.131062 &  0.870370 \\\\\n",
      "1 &    Diabetes &   0.007199 &   0.002294 &  0.058752 &  0.680399 \\\\\n",
      "2 &     Vehicle &   0.006845 &   0.002187 &  0.028808 &  0.927406 \\\\\n",
      "3 &       Vowel &   0.008149 &   0.002185 &  0.028464 &  0.975712 \\\\\n",
      "4 &        Iris &   0.003684 &   0.001805 &  0.020107 &  0.954545 \\\\\n",
      "5 &      Letter &   0.118962 &   0.003134 &  0.285794 &  0.862200 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreTree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_tree,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreTree.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreTree)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9272079772079772 +- 0.03655976731195557\n",
      "Tiempo medio en ejecutarse el método (train): 0.044843220710754396 +- 0.044843220710754396s\n",
      "Tiempo medio en ejecutarse el método (score): 0.007536458969116211 +- 0.007536458969116211s\n",
      "Tiempo en ejecutarse la búsqueda 0.10985589027404785s, (0.0018309315045674643 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.7602843315184512 +- 0.060405141892844516\n",
      "Tiempo medio en ejecutarse el método (train): 0.06925463676452637 +- 0.06925463676452637s\n",
      "Tiempo medio en ejecutarse el método (score): 0.01099848747253418 +- 0.01099848747253418s\n",
      "Tiempo en ejecutarse la búsqueda 0.1377706527709961s, (0.0022961775461832683 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8169394841269841 +- 0.03453561142295125\n",
      "Tiempo medio en ejecutarse el método (train): 0.07515547275543213 +- 0.07515547275543213s\n",
      "Tiempo medio en ejecutarse el método (score): 0.01232907772064209 +- 0.01232907772064209s\n",
      "Tiempo en ejecutarse la búsqueda 0.1324446201324463s, (0.0022074103355407713 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9500720720720721 +- 0.013561105384699672\n",
      "Tiempo medio en ejecutarse el método (train): 0.0601362943649292 +- 0.0601362943649292s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0077800750732421875 +- 0.0077800750732421875s\n",
      "Tiempo en ejecutarse la búsqueda 0.10480070114135742s, (0.0017466783523559571 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9727272727272727 +- 0.0416597790450531\n",
      "Tiempo medio en ejecutarse el método (train): 0.037349820137023926 +- 0.037349820137023926s\n",
      "Tiempo medio en ejecutarse el método (score): 0.004720735549926758 +- 0.004720735549926758s\n",
      "Tiempo en ejecutarse la búsqueda 0.07013678550720215s, (0.0011689464251200359 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9206 +- 0.006782002326419206\n",
      "Tiempo medio en ejecutarse el método (train): 13.751698064804078 +- 13.751698064804078s\n",
      "Tiempo medio en ejecutarse el método (score): 8.534578990936279 +- 8.534578990936279s\n",
      "Tiempo en ejecutarse la búsqueda 22.92805004119873s, (0.3821341673533122 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &     TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.044843 &   0.007536 &   0.109856 &  0.927208 \\\\\n",
      "1 &    Diabetes &   0.069255 &   0.010998 &   0.137771 &  0.760284 \\\\\n",
      "2 &     Vehicle &   0.075155 &   0.012329 &   0.132445 &  0.816939 \\\\\n",
      "3 &       Vowel &   0.060136 &   0.007780 &   0.104801 &  0.950072 \\\\\n",
      "4 &        Iris &   0.037350 &   0.004721 &   0.070137 &  0.972727 \\\\\n",
      "5 &      Letter &  13.751698 &   8.534579 &  22.928050 &  0.920600 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreBaggingSVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_BaggingSVM,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreBaggingSVM.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreBaggingSVM)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9122507122507123 +- 0.04213828352019221\n",
      "Tiempo medio en ejecutarse el método (train): 0.0751305341720581 +- 0.0751305341720581s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0045659542083740234 +- 0.0045659542083740234s\n",
      "Tiempo en ejecutarse la búsqueda 0.11945891380310059s, (0.001990981896718343 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.7535390199637023 +- 0.05073341056061811\n",
      "Tiempo medio en ejecutarse el método (train): 0.04737944602966308 +- 0.04737944602966308s\n",
      "Tiempo medio en ejecutarse el método (score): 0.004109096527099609 +- 0.004109096527099609s\n",
      "Tiempo en ejecutarse la búsqueda 0.07030749320983887s, (0.0011717915534973145 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9509920634920634 +- 0.024100507774603035\n",
      "Tiempo medio en ejecutarse el método (train): 0.057846474647521975 +- 0.057846474647521975s\n",
      "Tiempo medio en ejecutarse el método (score): 0.004347896575927735 +- 0.004347896575927735s\n",
      "Tiempo en ejecutarse la búsqueda 0.0910031795501709s, (0.001516719659169515 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9838198198198198 +- 0.011748189899378448\n",
      "Tiempo medio en ejecutarse el método (train): 0.05928447246551514 +- 0.05928447246551514s\n",
      "Tiempo medio en ejecutarse el método (score): 0.004340910911560058 +- 0.004340910911560058s\n",
      "Tiempo en ejecutarse la búsqueda 0.09021806716918945s, (0.0015036344528198242 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9454545454545455 +- 0.06030226891555273\n",
      "Tiempo medio en ejecutarse el método (train): 0.032737898826599124 +- 0.032737898826599124s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0041912317276000975 +- 0.0041912317276000975s\n",
      "Tiempo en ejecutarse la búsqueda 0.05590701103210449s, (0.0009317835172017416 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9221999999999999 +- 0.006864077181643257\n",
      "Tiempo medio en ejecutarse el método (train): 0.881441617012024 +- 0.881441617012024s\n",
      "Tiempo medio en ejecutarse el método (score): 0.012939453125 +- 0.012939453125s\n",
      "Tiempo en ejecutarse la búsqueda 1.1136679649353027s, (0.018561132748921714 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &    TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.075131 &   0.004566 &  0.119459 &  0.912251 \\\\\n",
      "1 &    Diabetes &   0.047379 &   0.004109 &  0.070307 &  0.753539 \\\\\n",
      "2 &     Vehicle &   0.057846 &   0.004348 &  0.091003 &  0.950992 \\\\\n",
      "3 &       Vowel &   0.059284 &   0.004341 &  0.090218 &  0.983820 \\\\\n",
      "4 &        Iris &   0.032738 &   0.004191 &  0.055907 &  0.945455 \\\\\n",
      "5 &      Letter &   0.881442 &   0.012939 &  1.113668 &  0.922200 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreBaggingTree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_BaggingTree,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreBaggingTree.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreBaggingTree)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.6159544159544159 +- 0.009602449883961674\n",
      "Tiempo medio en ejecutarse el método (train): 0.14536588191986083 +- 0.14536588191986083s\n",
      "Tiempo medio en ejecutarse el método (score): 0.010915851593017578 +- 0.010915851593017578s\n",
      "Tiempo en ejecutarse la búsqueda 0.5188491344451904s, (0.008647485574086507 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.6458560193587417 +- 0.006837393933965337\n",
      "Tiempo medio en ejecutarse el método (train): 0.29889588356018065 +- 0.29889588356018065s\n",
      "Tiempo medio en ejecutarse el método (score): 0.019411635398864747 +- 0.019411635398864747s\n",
      "Tiempo en ejecutarse la búsqueda 1.3182523250579834s, (0.021970872084299722 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.7602678571428572 +- 0.005332283591419313\n",
      "Tiempo medio en ejecutarse el método (train): 0.2613798141479492 +- 0.2613798141479492s\n",
      "Tiempo medio en ejecutarse el método (score): 0.012282705307006836 +- 0.012282705307006836s\n",
      "Tiempo en ejecutarse la búsqueda 1.527435541152954s, (0.025457259019215903 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9163423423423425 +- 0.005160864890530518\n",
      "Tiempo medio en ejecutarse el método (train): 2.992864656448364 +- 2.992864656448364s\n",
      "Tiempo medio en ejecutarse el método (score): 0.14332239627838134 +- 0.14332239627838134s\n",
      "Tiempo en ejecutarse la búsqueda 3.7156081199645996s, (0.061926801999409996 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.3666666666666667 +- 0.031637292451244095\n",
      "Tiempo medio en ejecutarse el método (train): 0.25621833801269533 +- 0.25621833801269533s\n",
      "Tiempo medio en ejecutarse el método (score): 0.011872005462646485 +- 0.011872005462646485s\n",
      "Tiempo en ejecutarse la búsqueda 0.3316764831542969s, (0.0055279413859049475 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.08046666666666667 +- 0.014248742634585922\n",
      "Tiempo medio en ejecutarse el método (train): 1298.143928694725 +- 1298.143928694725s\n",
      "Tiempo medio en ejecutarse el método (score): 64.74819123744965 +- 64.74819123744965s\n",
      "Tiempo en ejecutarse la búsqueda 1393.2976653575897s, (23.22162775595983 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &    TimeTrain &  TimeScore &       TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &     0.145366 &   0.010916 &     0.518849 &  0.615954 \\\\\n",
      "1 &    Diabetes &     0.298896 &   0.019412 &     1.318252 &  0.645856 \\\\\n",
      "2 &     Vehicle &     0.261380 &   0.012283 &     1.527436 &  0.760268 \\\\\n",
      "3 &       Vowel &     2.992865 &   0.143322 &     3.715608 &  0.916342 \\\\\n",
      "4 &        Iris &     0.256218 &   0.011872 &     0.331676 &  0.366667 \\\\\n",
      "5 &      Letter &  1298.143929 &  64.748191 &  1393.297665 &  0.080467 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreBoosting1_SVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_AdaBoostSAMMESVM,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreBoosting1_SVM.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreBoosting1_SVM)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8628205128205128 +- 0.04613735592295677\n",
      "Tiempo medio en ejecutarse el método (train): 0.00831308364868164 +- 0.00831308364868164s\n",
      "Tiempo medio en ejecutarse el método (score): 0.001977705955505371 +- 0.001977705955505371s\n",
      "Tiempo en ejecutarse la búsqueda 0.11420869827270508s, (0.0019034783045450846 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.6804900181488203 +- 0.04820611422491956\n",
      "Tiempo medio en ejecutarse el método (train): 0.006333398818969727 +- 0.006333398818969727s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0016691446304321288 +- 0.0016691446304321288s\n",
      "Tiempo en ejecutarse la búsqueda 0.025470256805419922s, (0.00042450428009033203 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9353422619047619 +- 0.010934687667086433\n",
      "Tiempo medio en ejecutarse el método (train): 0.005640053749084472 +- 0.005640053749084472s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0017957687377929688 +- 0.0017957687377929688s\n",
      "Tiempo en ejecutarse la búsqueda 0.022655963897705078s, (0.00037759939829508463 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9784144144144147 +- 0.006591640159342768\n",
      "Tiempo medio en ejecutarse el método (train): 0.006309914588928223 +- 0.006309914588928223s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0017837762832641601 +- 0.0017837762832641601s\n",
      "Tiempo en ejecutarse la búsqueda 0.026072263717651367s, (0.00043453772862752277 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9545454545454545 +- 0.06098367211363062\n",
      "Tiempo medio en ejecutarse el método (train): 0.004027962684631348 +- 0.004027962684631348s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0018110036849975585 +- 0.0018110036849975585s\n",
      "Tiempo en ejecutarse la búsqueda 0.019563674926757812s, (0.00032606124877929685 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8648666666666666 +- 0.00896437393240599\n",
      "Tiempo medio en ejecutarse el método (train): 0.08498284816741944 +- 0.08498284816741944s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0025040388107299806 +- 0.0025040388107299806s\n",
      "Tiempo en ejecutarse la búsqueda 0.23721551895141602s, (0.0039535919825236 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &    TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.008313 &   0.001978 &  0.114209 &  0.862821 \\\\\n",
      "1 &    Diabetes &   0.006333 &   0.001669 &  0.025470 &  0.680490 \\\\\n",
      "2 &     Vehicle &   0.005640 &   0.001796 &  0.022656 &  0.935342 \\\\\n",
      "3 &       Vowel &   0.006310 &   0.001784 &  0.026072 &  0.978414 \\\\\n",
      "4 &        Iris &   0.004028 &   0.001811 &  0.019564 &  0.954545 \\\\\n",
      "5 &      Letter &   0.084983 &   0.002504 &  0.237216 &  0.864867 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreBoosting1_Tree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_AdaBoostSAMMETree,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreBoosting1_Tree.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreBoosting1_Tree)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AdaBoost with SVM and SAMMER_R is not supported"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nDatasets = []\\nTimeTrain = []\\nTimeScore = []\\nTimeCV = []\\nScoreBoosting2_SVM = []\\nfor i in data:\\n    init = time.time()\\n    cv = cross_validate(clf_AdaBoostSAMMERSVM,i[1], y=i[2],cv=10, n_jobs=-1, error_score=\\'raise\\')\\n    end = time.time()\\n    timeCV = end - init\\n    print(f\"\\n--------- {i[0]} ---------\")\\n    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv[\\'test_score\\'])} +- {np.std(cv[\\'test_score\\'])}\")\\n    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv[\\'fit_time\\'])} +- {np.mean(np.mean(cv[\\'fit_time\\']))}s\")\\n    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv[\\'score_time\\'])} +- {np.mean(np.mean(cv[\\'score_time\\']))}s\")\\n    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\\n    Datasets.append(i[0])\\n    TimeTrain.append(np.mean(cv[\\'fit_time\\']))\\n    TimeScore.append(np.mean(cv[\\'score_time\\']))\\n    TimeCV.append(timeCV)\\n    ScoreBoosting2_SVM.append(np.mean(cv[\\'test_score\\']))\\n\\nmy_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=Score)\\nSVMDF = pd.DataFrame (my_dict)\\nprint(SVMDF.to_latex())\\n'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreBoosting2_SVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_AdaBoostSAMMERSVM,i[1], y=i[2],cv=10, n_jobs=-1, error_score='raise')\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreBoosting2_SVM.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=Score)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8665242165242166 +- 0.05491282085574618\n",
      "Tiempo medio en ejecutarse el método (train): 0.007663512229919433 +- 0.007663512229919433s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0013726472854614258 +- 0.0013726472854614258s\n",
      "Tiempo en ejecutarse la búsqueda 0.43686938285827637s, (0.007281156380971273 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.6752571082879613 +- 0.05043957376081613\n",
      "Tiempo medio en ejecutarse el método (train): 0.004450702667236328 +- 0.004450702667236328s\n",
      "Tiempo medio en ejecutarse el método (score): 0.001280808448791504 +- 0.001280808448791504s\n",
      "Tiempo en ejecutarse la búsqueda 0.5096859931945801s, (0.008494766553243 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9353670634920634 +- 0.012828535622418924\n",
      "Tiempo medio en ejecutarse el método (train): 0.004993653297424317 +- 0.004993653297424317s\n",
      "Tiempo medio en ejecutarse el método (score): 0.001487398147583008 +- 0.001487398147583008s\n",
      "Tiempo en ejecutarse la búsqueda 0.01836705207824707s, (0.0003061175346374512 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9797657657657659 +- 0.006721493567137455\n",
      "Tiempo medio en ejecutarse el método (train): 0.004731941223144531 +- 0.004731941223144531s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0011875152587890625 +- 0.0011875152587890625s\n",
      "Tiempo en ejecutarse la búsqueda 0.01726555824279785s, (0.00028775930404663087 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9545454545454545 +- 0.06098367211363062\n",
      "Tiempo medio en ejecutarse el método (train): 0.0026885271072387695 +- 0.0026885271072387695s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0009922266006469726 +- 0.0009922266006469726s\n",
      "Tiempo en ejecutarse la búsqueda 0.011464595794677734s, (0.00019107659657796223 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.8633333333333335 +- 0.012092238098144695\n",
      "Tiempo medio en ejecutarse el método (train): 0.061181139945983884 +- 0.061181139945983884s\n",
      "Tiempo medio en ejecutarse el método (score): 0.002276015281677246 +- 0.002276015281677246s\n",
      "Tiempo en ejecutarse la búsqueda 0.19957971572875977s, (0.0033263285954793294 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &    TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.007664 &   0.001373 &  0.436869 &  0.866524 \\\\\n",
      "1 &    Diabetes &   0.004451 &   0.001281 &  0.509686 &  0.675257 \\\\\n",
      "2 &     Vehicle &   0.004994 &   0.001487 &  0.018367 &  0.935367 \\\\\n",
      "3 &       Vowel &   0.004732 &   0.001188 &  0.017266 &  0.979766 \\\\\n",
      "4 &        Iris &   0.002689 &   0.000992 &  0.011465 &  0.954545 \\\\\n",
      "5 &      Letter &   0.061181 &   0.002276 &  0.199580 &  0.863333 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreBoosting2_Tree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_AdaBoostSAMMERTree,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreBoosting2_Tree.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreBoosting2_Tree)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9235042735042736 +- 0.04227218477942589\n",
      "Tiempo medio en ejecutarse el método (train): 0.18839969635009765 +- 0.18839969635009765s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0014230012893676758 +- 0.0014230012893676758s\n",
      "Tiempo en ejecutarse la búsqueda 0.21954035758972168s, (0.0036590059598286947 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.7654869933454325 +- 0.05773715833974873\n",
      "Tiempo medio en ejecutarse el método (train): 0.10426268577575684 +- 0.10426268577575684s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0012633562088012694 +- 0.0012633562088012694s\n",
      "Tiempo en ejecutarse la búsqueda 0.1313488483428955s, (0.002189147472381592 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9542410714285714 +- 0.021733111734585763\n",
      "Tiempo medio en ejecutarse el método (train): 0.1734703302383423 +- 0.1734703302383423s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0014028549194335938 +- 0.0014028549194335938s\n",
      "Tiempo en ejecutarse la búsqueda 0.19730854034423828s, (0.0032884756724039714 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9878738738738739 +- 0.011177867798122125\n",
      "Tiempo medio en ejecutarse el método (train): 0.23249878883361816 +- 0.23249878883361816s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0015064001083374024 +- 0.0015064001083374024s\n",
      "Tiempo en ejecutarse la búsqueda 0.26279711723327637s, (0.004379951953887939 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9545454545454545 +- 0.06098367211363062\n",
      "Tiempo medio en ejecutarse el método (train): 0.17625677585601807 +- 0.17625677585601807s\n",
      "Tiempo medio en ejecutarse el método (score): 0.0013308048248291016 +- 0.0013308048248291016s\n",
      "Tiempo en ejecutarse la búsqueda 0.22205352783203125s, (0.003700892130533854 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "Score de la Validación Cruzada:\n",
      "   score = 0.9173333333333333 +- 0.011325487480310386\n",
      "Tiempo medio en ejecutarse el método (train): 63.89836778640747 +- 63.89836778640747s\n",
      "Tiempo medio en ejecutarse el método (score): 0.06536240577697754 +- 0.06536240577697754s\n",
      "Tiempo en ejecutarse la búsqueda 67.11561965942383s, (1.118593660990397 min)\n",
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeTrain &  TimeScore &     TimeCV &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &   0.188400 &   0.001423 &   0.219540 &  0.923504 \\\\\n",
      "1 &    Diabetes &   0.104263 &   0.001263 &   0.131349 &  0.765487 \\\\\n",
      "2 &     Vehicle &   0.173470 &   0.001403 &   0.197309 &  0.954241 \\\\\n",
      "3 &       Vowel &   0.232499 &   0.001506 &   0.262797 &  0.987874 \\\\\n",
      "4 &        Iris &   0.176257 &   0.001331 &   0.222054 &  0.954545 \\\\\n",
      "5 &      Letter &  63.898368 &   0.065362 &  67.115620 &  0.917333 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeTrain = []\n",
    "TimeScore = []\n",
    "TimeCV = []\n",
    "ScoreGradBoost = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    cv = cross_validate(clf_GradBoost,i[1], y=i[2],cv=10, n_jobs=-1)\n",
    "    end = time.time()\n",
    "    timeCV = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"Score de la Validación Cruzada:\\n   score = {np.mean(cv['test_score'])} +- {np.std(cv['test_score'])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (train): {np.mean(cv['fit_time'])} +- {np.mean(np.mean(cv['fit_time']))}s\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método (score): {np.mean(cv['score_time'])} +- {np.mean(np.mean(cv['score_time']))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeCV}s, ({timeCV/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeTrain.append(np.mean(cv['fit_time']))\n",
    "    TimeScore.append(np.mean(cv['score_time']))\n",
    "    TimeCV.append(timeCV)\n",
    "    ScoreGradBoost.append(np.mean(cv['test_score']))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeTrain=TimeTrain, TimeScore=TimeScore,TimeCV=TimeCV, Score=ScoreGradBoost)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SVM      Tree  BaggingSVM  BaggingTree  Boosting1_SVM  Boosting1_Tree  \\\n",
      "0  0.927208  0.870370    0.927208     0.912251       0.615954        0.862821   \n",
      "1  0.755112  0.680399    0.760284     0.753539       0.645856        0.680490   \n",
      "2  0.823264  0.927406    0.816939     0.950992       0.760268        0.935342   \n",
      "3  0.946054  0.975712    0.950072     0.983820       0.916342        0.978414   \n",
      "4  0.981818  0.954545    0.972727     0.945455       0.366667        0.954545   \n",
      "5  0.920600  0.862200    0.920600     0.922200       0.080467        0.864867   \n",
      "\n",
      "   Boosting2_Tree  GradBoost  \n",
      "0        0.866524   0.923504  \n",
      "1        0.675257   0.765487  \n",
      "2        0.935367   0.954241  \n",
      "3        0.979766   0.987874  \n",
      "4        0.954545   0.954545  \n",
      "5        0.863333   0.917333  \n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} &       SVM &      Tree &  BaggingSVM &  BaggingTree &  Boosting1\\_SVM &  Boosting1\\_Tree &  Boosting2\\_Tree &  GradBoost \\\\\n",
      "\\midrule\n",
      "0 &  0.927208 &  0.870370 &    0.927208 &     0.912251 &       0.615954 &        0.862821 &        0.866524 &   0.923504 \\\\\n",
      "1 &  0.755112 &  0.680399 &    0.760284 &     0.753539 &       0.645856 &        0.680490 &        0.675257 &   0.765487 \\\\\n",
      "2 &  0.823264 &  0.927406 &    0.816939 &     0.950992 &       0.760268 &        0.935342 &        0.935367 &   0.954241 \\\\\n",
      "3 &  0.946054 &  0.975712 &    0.950072 &     0.983820 &       0.916342 &        0.978414 &        0.979766 &   0.987874 \\\\\n",
      "4 &  0.981818 &  0.954545 &    0.972727 &     0.945455 &       0.366667 &        0.954545 &        0.954545 &   0.954545 \\\\\n",
      "5 &  0.920600 &  0.862200 &    0.920600 &     0.922200 &       0.080467 &        0.864867 &        0.863333 &   0.917333 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compareDF = pd.DataFrame()\n",
    "compareDF['SVM'] = ScoreSVM\n",
    "compareDF['Tree'] = ScoreTree\n",
    "compareDF['BaggingSVM'] = ScoreBaggingSVM\n",
    "compareDF['BaggingTree'] = ScoreBaggingTree\n",
    "compareDF['Boosting1_SVM'] = ScoreBoosting1_SVM\n",
    "compareDF['Boosting1_Tree'] = ScoreBoosting1_Tree\n",
    "compareDF['Boosting2_Tree'] = ScoreBoosting2_Tree\n",
    "compareDF['GradBoost'] = ScoreGradBoost\n",
    "compareDF.to_csv(\"performance.csv\", index=False)\n",
    "print(compareDF)\n",
    "print(compareDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def compute_iman_davenport_statistic(performance_matrix):\n",
    "  # Compute the ranks of the model performance on each dataset\n",
    "  ranks = np.apply_along_axis(lambda x: len(x) - np.argsort(np.argsort(x)), 1, performance_matrix)\n",
    "\n",
    "  # Sum the ranks for each model across all datasets\n",
    "  rank_sums = np.sum(ranks, axis=1)\n",
    "\n",
    "  # Compute the iman Davenport statistic\n",
    "  iman_davenport_statistic = (np.max(rank_sums) - np.min(rank_sums)) / performance_matrix.shape[1]\n",
    "\n",
    "  return iman_davenport_statistic\n",
    "\n",
    "def compute_p_value(iman_davenport_statistic, num_models, num_datasets):\n",
    "  # Compute the degrees of freedom for the iman Davenport test\n",
    "  df = num_models - 1\n",
    "\n",
    "  # Compute the p-value using the chi-squared distribution\n",
    "  p_value = 1 - chi2.cdf(iman_davenport_statistic, df)\n",
    "\n",
    "  return p_value\n",
    "\n",
    "def iman_davenport_test(performance_matrix, significance_level):\n",
    "  # Compute the iman Davenport statistic and p-value\n",
    "  iman_davenport_statistic = compute_iman_davenport_statistic(performance_matrix)\n",
    "  p_value = compute_p_value(iman_davenport_statistic, performance_matrix.shape[0], performance_matrix.shape[1])\n",
    "\n",
    "  # Determine whether the difference in performance between the models is statistically significant\n",
    "  if p_value < significance_level:\n",
    "    print(f\"The difference in performance between the models is statistically significant (p = {p_value:.3f})\")\n",
    "  else:\n",
    "    print(f\"The difference in performance between the models is not statistically significant (p = {p_value:.3f})\")\n",
    "  return p_value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference in performance between the models is not statistically significant (p = 1.000)\n"
     ]
    }
   ],
   "source": [
    "performance_matrix = pd.read_csv(\"performance.csv\")\n",
    "# Run the iman Davenport test\n",
    "p_value = iman_davenport_test(performance_matrix, 0.05)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# If there are significant differences between the models, then apply the wilcoxon test to determine which models are significantly different\n",
    "if p_value < 0.05:\n",
    "  # Compute the pairwise differences between the models\n",
    "  pairwise_differences = np.apply_along_axis(lambda x: x - x[:, None], 1, performance_matrix)\n",
    "\n",
    "  # Compute the p-values for the pairwise differences using the Wilcoxon signed-rank test\n",
    "  p_values = np.apply_along_axis(lambda x: wilcoxon(x, zero_method=\"wilcox\")[1], 1, pairwise_differences)\n",
    "\n",
    "  # Compute the Bonferroni correction\n",
    "  bonferroni_correction = 0.05 / (p_values.shape[0] * (p_values.shape[0] - 1) / 2)\n",
    "\n",
    "  # Determine which models are significantly different\n",
    "  significant_differences = np.argwhere(p_values < bonferroni_correction)\n",
    "\n",
    "  # Print the significant differences\n",
    "  for difference in significant_differences:\n",
    "    print(f\"Model {difference[0]} is significantly different from model {difference[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison using GridSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "parametersSVM = [\n",
    "    {\"kernel\": [\"rbf\"], \"C\": [1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]}\n",
    "]\n",
    "parametersTree = {\n",
    "    'criterion':['gini', 'entropy', 'log_loss'],\n",
    "    'splitter' : ['best', 'random']\n",
    "}\n",
    "parametersSVMBagging = [\n",
    "    {\n",
    "    'n_estimators':[10], # Numero de estimators = 10 porque si no tarda demasiado\n",
    "    \"estimator__kernel\": [\"rbf\"],\n",
    "    \"estimator__C\": [1, 10, 100, 1000],\n",
    "    'estimator__gamma': [0.01, 0.1, 1],\n",
    "    #'max_samples': [0.75, 1]\n",
    "    # Saltan warnings si aleatoriamente solo seleccionamos instancias de una clase. Podríamos ignorar dichos fits o capturar los warning. Eliminamos el problema directamente\n",
    "    'max_features': [0.5, 0.75, 1],\n",
    "    'bootstrap': [True, False]\n",
    "    },\n",
    "    {\n",
    "    'n_estimators':[10], # Numero de estimators = 10 porque si no tarda demasiado\n",
    "    \"estimator__kernel\": [\"linear\"],\n",
    "    \"estimator__C\": [1, 10, 100, 1000],\n",
    "    #'max_samples': [0.75, 1]\n",
    "    # Saltan warnings si aleatoriamente solo seleccionamos instancias de una clase. Podríamos ignorar dichos fits o capturar los warning. Eliminamos el problema directamente\n",
    "    'max_features': [0.5, 0.75, 1],\n",
    "    'bootstrap': [True, False]\n",
    "    }\n",
    "]\n",
    "parametersTreeBagging = {\n",
    "    'estimator__criterion':['gini', 'entropy', 'log_loss'],\n",
    "    'estimator__splitter' : ['best', 'random'],\n",
    "    # {'max_samples': [0.75, 1],\n",
    "    'max_features': [0.5, 0.75, 1],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "parametersSVMBoosting = [\n",
    "    {\n",
    "    \"estimator__kernel\": [\"rbf\"],\n",
    "    \"estimator__C\": [1, 10, 100, 1000],\n",
    "    'estimator__gamma': [0.01, 0.1, 1],\n",
    "    'n_estimators':[25, 50],\n",
    "    'learning_rate':[0.1, 1, 10]\n",
    "    },{\n",
    "    \"estimator__kernel\": [\"linear\"],\n",
    "    \"estimator__C\": [1, 10, 100, 1000],\n",
    "    'n_estimators':[25, 50, 75],\n",
    "    'learning_rate':[0.1, 1, 10]\n",
    "    }\n",
    "]\n",
    "parametersTreeBoosting = {\n",
    "    'estimator__criterion':['gini', 'entropy', 'log_loss'],\n",
    "    'estimator__splitter' : ['best', 'random'],\n",
    "    'n_estimators':[25, 50],\n",
    "    'learning_rate':[0.1,1,10]\n",
    "}\n",
    "parametersGradBoosting = {\n",
    "    \"loss\" : ['log_loss', 'deviance', 'exponential'],\n",
    "    'learning_rate' : [0.01, 0.1, 1],\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'warm_start': [True, False]\n",
    "}\n",
    "\n",
    "optimalSVM = GridSearchCV(estimator=clf_svm, cv=10, param_grid=parametersSVM, n_jobs=-1)\n",
    "optimalTree = GridSearchCV(estimator=clf_tree, cv=10, param_grid=parametersTree, n_jobs=-1)\n",
    "optimalSVMBag = GridSearchCV(estimator=clf_BaggingSVM, cv=10, param_grid=parametersSVMBagging, n_jobs=-1)\n",
    "optimalTreeBag = GridSearchCV(estimator=clf_BaggingTree, cv=10, param_grid=parametersTreeBagging, n_jobs=-1)\n",
    "optimalSVMBoost1 = GridSearchCV(estimator=clf_AdaBoostSAMMESVM, cv=10, param_grid=parametersSVMBoosting, n_jobs=-1)\n",
    "optimalTreeBoost1 = GridSearchCV(estimator=clf_AdaBoostSAMMETree, cv=10, param_grid=parametersTreeBoosting, n_jobs=-1)\n",
    "optimalSVMBoost2 = GridSearchCV(estimator=clf_AdaBoostSAMMERSVM, cv=10, param_grid=parametersTreeBoosting, n_jobs=-1)\n",
    "optimalTreeBoost2 = GridSearchCV(estimator=clf_AdaBoostSAMMERTree, cv=10, param_grid=parametersTreeBoosting, n_jobs=-1)\n",
    "optimalGradBoost = GridSearchCV(estimator=clf_GradBoost, cv=10, param_grid=parametersGradBoosting, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVM:\n",
      "    Best params -> {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "    Best score -> 0.931054131054131\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.9886363636363636\n",
      "Tiempo medio en ejecutarse el método: 0.01968134343624115 +- 0.007482357550970337s\n",
      "Tiempo en ejecutarse la búsqueda 2.148488759994507s, (0.03580814599990845 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVM:\n",
      "    Best params -> {'C': 10, 'kernel': 'linear'}\n",
      "    Best score -> 0.7724137931034483\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.7708333333333334\n",
      "Tiempo medio en ejecutarse el método: 10.642622084915638 +- 3.6427488372419266s\n",
      "Tiempo en ejecutarse la búsqueda 177.8575484752655s, (2.9642924745877584 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVM:\n",
      "    Best params -> {'C': 1, 'kernel': 'linear'}\n",
      "    Best score -> 0.9779265873015873\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.9575471698113207\n",
      "Tiempo medio en ejecutarse el método: 0.8645733505487442 +- 0.5410312962418407s\n",
      "Tiempo en ejecutarse la búsqueda 27.743560314178467s, (0.46239267190297445 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVM:\n",
      "    Best params -> {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "    Best score -> 1.0\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 1.0\n",
      "Tiempo medio en ejecutarse el método: 0.02575916200876236 +- 0.014138852749983197s\n",
      "Tiempo en ejecutarse la búsqueda 0.8849797248840332s, (0.014749662081400553 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVM:\n",
      "    Best params -> {'C': 1, 'kernel': 'linear'}\n",
      "    Best score -> 0.990909090909091\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.9736842105263158\n",
      "Tiempo medio en ejecutarse el método: 0.0018980309367179872 +- 0.0003154921950096859s\n",
      "Tiempo en ejecutarse la búsqueda 0.09299159049987793s, (0.001549859841664632 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVM:\n",
      "    Best params -> {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "    Best score -> 0.9718\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.9724\n",
      "Tiempo medio en ejecutarse el método: 79.30389883369207 +- 3.503608401790226s\n",
      "Tiempo en ejecutarse la búsqueda 1080.8552613258362s, (18.0142543554306 min)\n",
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeMethod &   TimeSearch &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &    0.019681 &     2.148489 &  0.988636 \\\\\n",
      "1 &    Diabetes &   10.642622 &   177.857548 &  0.770833 \\\\\n",
      "2 &     Vehicle &    0.864573 &    27.743560 &  0.957547 \\\\\n",
      "3 &       Vowel &    0.025759 &     0.884980 &  1.000000 \\\\\n",
      "4 &        Iris &    0.001898 &     0.092992 &  0.973684 \\\\\n",
      "5 &      Letter &   79.303899 &  1080.855261 &  0.972400 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreSVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalSVM.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente SVM:\")\n",
    "    print(f'    Best params -> {optimalSVM.best_params_}')\n",
    "    print(f'    Best score -> {optimalSVM.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalSVM.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalSVM.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalSVM.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalSVM.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreSVM.append(optimalSVM.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreSVM)\n",
    "SVMDF = pd.DataFrame (my_dict)\n",
    "print(SVMDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "La mejor accuracy se obtuvo con el siguiente Tree:\n",
      "    Best params -> {'criterion': 'log_loss', 'splitter': 'random'}\n",
      "    Best score -> 0.8971509971509972\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.8863636363636364\n",
      "Tiempo medio en ejecutarse el método: 0.004364693164825439 +- 0.0005929095087477455s\n",
      "Tiempo en ejecutarse la búsqueda 0.19702720642089844s, (0.003283786773681641 min)\n",
      "\n",
      "--------- Diabetes ---------\n",
      "La mejor accuracy se obtuvo con el siguiente Tree:\n",
      "    Best params -> {'criterion': 'entropy', 'splitter': 'best'}\n",
      "    Best score -> 0.7065033272837267\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.7447916666666666\n",
      "Tiempo medio en ejecutarse el método: 0.003492077191670736 +- 0.0002670651082585429s\n",
      "Tiempo en ejecutarse la búsqueda 0.08609962463378906s, (0.0014349937438964844 min)\n",
      "\n",
      "--------- Vehicle ---------\n",
      "La mejor accuracy se obtuvo con el siguiente Tree:\n",
      "    Best params -> {'criterion': 'entropy', 'splitter': 'random'}\n",
      "    Best score -> 0.9464285714285714\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.8915094339622641\n",
      "Tiempo medio en ejecutarse el método: 0.0033310254414876304 +- 0.0005076516422809724s\n",
      "Tiempo en ejecutarse la búsqueda 0.7302579879760742s, (0.012170966466267903 min)\n",
      "\n",
      "--------- Vowel ---------\n",
      "La mejor accuracy se obtuvo con el siguiente Tree:\n",
      "    Best params -> {'criterion': 'entropy', 'splitter': 'random'}\n",
      "    Best score -> 0.9838378378378378\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.9959514170040485\n",
      "Tiempo medio en ejecutarse el método: 0.0032692790031433106 +- 0.00040722047598768267s\n",
      "Tiempo en ejecutarse la búsqueda 0.4828972816467285s, (0.008048288027445475 min)\n",
      "\n",
      "--------- Iris ---------\n",
      "La mejor accuracy se obtuvo con el siguiente Tree:\n",
      "    Best params -> {'criterion': 'gini', 'splitter': 'best'}\n",
      "    Best score -> 0.9545454545454545\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.8947368421052632\n",
      "Tiempo medio en ejecutarse el método: 0.0019045750300089516 +- 0.00040513818123714615s\n",
      "Tiempo en ejecutarse la búsqueda 0.04361701011657715s, (0.0007269501686096192 min)\n",
      "\n",
      "--------- Letter ---------\n",
      "La mejor accuracy se obtuvo con el siguiente Tree:\n",
      "    Best params -> {'criterion': 'entropy', 'splitter': 'best'}\n",
      "    Best score -> 0.8744\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.8746\n",
      "Tiempo medio en ejecutarse el método: 0.04991275469462076 +- 0.0034523774272351994s\n",
      "Tiempo en ejecutarse la búsqueda 0.39173388481140137s, (0.006528898080190023 min)\n",
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "{} &     Dataset &  TimeMethod &  TimeSearch &     Score \\\\\n",
      "\\midrule\n",
      "0 &  Ionosphere &    0.004365 &    0.197027 &  0.886364 \\\\\n",
      "1 &    Diabetes &    0.003492 &    0.086100 &  0.744792 \\\\\n",
      "2 &     Vehicle &    0.003331 &    0.730258 &  0.891509 \\\\\n",
      "3 &       Vowel &    0.003269 &    0.482897 &  0.995951 \\\\\n",
      "4 &        Iris &    0.001905 &    0.043617 &  0.894737 \\\\\n",
      "5 &      Letter &    0.049913 &    0.391734 &  0.874600 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreTree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalTree.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente Tree:\")\n",
    "    print(f'    Best params -> {optimalTree.best_params_}')\n",
    "    print(f'    Best score -> {optimalTree.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalTree.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalTree.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalTree.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalTree.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreTree.append(optimalTree.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreTree)\n",
    "TreeDF = pd.DataFrame (my_dict)\n",
    "print(TreeDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- Ionosphere ---------\n",
      "La mejor accuracy se obtuvo con el siguiente SVMBag:\n",
      "    Best params -> {'bootstrap': False, 'estimator__C': 1000, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'max_features': 0.75, 'n_estimators': 10}\n",
      "    Best score -> 0.9464387464387466\n",
      "Si usamos el dataset de test, obtenemos el siguiente resultado:\n",
      "    score = 0.9204545454545454\n",
      "Tiempo medio en ejecutarse el método: 0.5599615052342415 +- 0.15056221420694077s\n",
      "Tiempo en ejecutarse la búsqueda 37.03996706008911s, (0.6173327843348185 min)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m data:\n\u001B[1;32m      6\u001B[0m     init \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 7\u001B[0m     \u001B[43moptimalSVMBag\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      9\u001B[0m     timeSearch \u001B[38;5;241m=\u001B[39m end \u001B[38;5;241m-\u001B[39m init\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    871\u001B[0m     )\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1389\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1387\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1388\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1389\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/concurrent/futures/_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/anaconda3/envs/Galactica/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreBaggingSVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalSVMBag.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente SVMBag:\")\n",
    "    print(f'    Best params -> {optimalSVMBag.best_params_}')\n",
    "    print(f'    Best score -> {optimalSVMBag.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalSVMBag.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalSVMBag.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalSVMBag.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalSVMBag.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreBaggingSVM.append(optimalSVMBag.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreBaggingSVM)\n",
    "SVMBagDF = pd.DataFrame (my_dict)\n",
    "print(SVMBagDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreBaggingTree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalTreeBag.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente TreeBag:\")\n",
    "    print(f'    Best params -> {optimalTreeBag.best_params_}')\n",
    "    print(f'    Best score -> {optimalTreeBag.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalTreeBag.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalTreeBag.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalTreeBag.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalTreeBag.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreBaggingTree.append(optimalTreeBag.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreBaggingTree)\n",
    "TreeBagDF = pd.DataFrame (my_dict)\n",
    "print(TreeBagDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreBoosting1_SVM = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalSVMBoost1.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente SVMBoost1:\")\n",
    "    print(f'    Best params -> {optimalSVMBoost1.best_params_}')\n",
    "    print(f'    Best score -> {optimalSVMBoost1.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalSVMBoost1.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalSVMBoost1.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalSVMBoost1.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalSVMBoost1.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreBoosting1_SVM.append(optimalSVMBoost1.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreBoosting1_SVM)\n",
    "SVMBoost1DF = pd.DataFrame (my_dict)\n",
    "print(SVMBoost1DF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreBoosting1_Tree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalTreeBoost1.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente TreeBoost1:\")\n",
    "    print(f'    Best params -> {optimalTreeBoost1.best_params_}')\n",
    "    print(f'    Best score -> {optimalTreeBoost1.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalTreeBoost1.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalTreeBoost1.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalTreeBoost1.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalTreeBoost1.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreBoosting1_Tree.append(optimalTreeBoost1.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreBoosting1_Tree)\n",
    "TreeBoost1DF = pd.DataFrame (my_dict)\n",
    "print(TreeBoost1DF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "Score = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalSVMBoost2.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente SVMBoost2:\")\n",
    "    print(f'    Best params -> {optimalSVMBoost2.best_params_}')\n",
    "    print(f'    Best score -> {optimalSVMBoost2.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalSVMBoost2.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalSVMBoost2.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalSVMBoost2.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalSVMBoost2.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    Score.append(optimalSVMBoost2.score(i[3], i[4]))\n",
    "\n",
    "d7 = dict(SVM_Boost2=Score)\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=Score)\n",
    "SVMBoost2DF = pd.DataFrame (my_dict)\n",
    "print(SVMBoost2DF.to_latex())\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreBoosting2_Tree = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalTreeBoost2.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente TreeBoost2:\")\n",
    "    print(f'    Best params -> {optimalTreeBoost2.best_params_}')\n",
    "    print(f'    Best score -> {optimalTreeBoost2.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalTreeBoost2.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalTreeBoost2.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalTreeBoost2.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalTreeBoost2.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreBoosting2_Tree.append(optimalTreeBoost2.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreBoosting2_Tree)\n",
    "TreeBoost2DF = pd.DataFrame (my_dict)\n",
    "print(TreeBoost2DF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Datasets = []\n",
    "TimeSearch = []\n",
    "TimeMethod = []\n",
    "ScoreGradBoost = []\n",
    "for i in data:\n",
    "    init = time.time()\n",
    "    optimalGradBoost.fit(i[1], i[2])\n",
    "    end = time.time()\n",
    "    timeSearch = end - init\n",
    "    print(f\"\\n--------- {i[0]} ---------\")\n",
    "    print(f\"La mejor accuracy se obtuvo con el siguiente GradBoost:\")\n",
    "    print(f'    Best params -> {optimalGradBoost.best_params_}')\n",
    "    print(f'    Best score -> {optimalGradBoost.best_score_}')\n",
    "\n",
    "    print(f\"Si usamos el dataset de test, obtenemos el siguiente resultado:\")\n",
    "    print(f\"    score = {optimalGradBoost.score(i[3], i[4])}\")\n",
    "    print(f\"Tiempo medio en ejecutarse el método: {np.mean(optimalGradBoost.cv_results_.get('mean_fit_time'))} +- {np.mean(optimalGradBoost.cv_results_.get('std_fit_time'))}s\")\n",
    "    print(f\"Tiempo en ejecutarse la búsqueda {timeSearch}s, ({timeSearch/60} min)\")\n",
    "    Datasets.append(i[0])\n",
    "    TimeMethod.append(np.mean(optimalGradBoost.cv_results_.get('mean_fit_time')))\n",
    "    TimeSearch.append(timeSearch)\n",
    "    ScoreGradBoost.append(optimalGradBoost.score(i[3], i[4]))\n",
    "\n",
    "my_dict = dict(Dataset=Datasets,TimeMethod=TimeMethod,TimeSearch=TimeSearch, Score=ScoreGradBoost)\n",
    "GradBoostDF = pd.DataFrame (my_dict)\n",
    "print(GradBoostDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compareDF = pd.DataFrame()\n",
    "compareDF['SVM'] = ScoreSVM\n",
    "compareDF['Tree'] = ScoreTree\n",
    "compareDF['BaggingSVM'] = ScoreBaggingSVM\n",
    "compareDF['BaggingTree'] = ScoreBaggingTree\n",
    "compareDF['Boosting1_SVM'] = ScoreBoosting1_SVM\n",
    "compareDF['Boosting1_Tree'] = ScoreBoosting1_Tree\n",
    "compareDF['Boosting2_Tree'] = ScoreBoosting2_Tree\n",
    "compareDF['GradBoost'] = ScoreGradBoost\n",
    "compareDF.to_csv(\"performanceGridSearch.csv\", index=False)\n",
    "print(compareDF)\n",
    "print(compareDF.to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iman Davenport test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def compute_imon_davenport_statistic(performance_matrix):\n",
    "  # Compute the ranks of the model performance on each dataset\n",
    "  ranks = np.apply_along_axis(lambda x: len(x) - np.argsort(np.argsort(x)), 1, performance_matrix)\n",
    "\n",
    "  # Sum the ranks for each model across all datasets\n",
    "  rank_sums = np.sum(ranks, axis=1)\n",
    "\n",
    "  # Compute the Imon Davenport statistic\n",
    "  imon_davenport_statistic = (np.max(rank_sums) - np.min(rank_sums)) / performance_matrix.shape[1]\n",
    "\n",
    "  return imon_davenport_statistic\n",
    "\n",
    "def compute_p_value(imon_davenport_statistic, num_models, num_datasets):\n",
    "  # Compute the degrees of freedom for the Imon Davenport test\n",
    "  df = num_models - 1\n",
    "\n",
    "  # Compute the p-value using the chi-squared distribution\n",
    "  p_value = 1 - chi2.cdf(imon_davenport_statistic, df)\n",
    "\n",
    "  return p_value\n",
    "\n",
    "def imon_davenport_test(performance_matrix, significance_level):\n",
    "  # Compute the Imon Davenport statistic and p-value\n",
    "  imon_davenport_statistic = compute_imon_davenport_statistic(performance_matrix)\n",
    "  p_value = compute_p_value(imon_davenport_statistic, performance_matrix.shape[0], performance_matrix.shape[1])\n",
    "\n",
    "  # Determine whether the difference in performance between the models is statistically significant\n",
    "  if p_value < significance_level:\n",
    "    print(f\"The difference in performance between the models is statistically significant (p = {p_value:.3f})\")\n",
    "  else:\n",
    "    print(f\"The difference in performance between the models is not statistically significant (p = {p_value:.3f})\")\n",
    "  return p_value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "performance_matrix = pd.read_csv(\"performance.csv\")\n",
    "# Run the Imon Davenport test\n",
    "p_value = imon_davenport_test(performance_matrix, 0.05)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wilcoxon Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If there are significant differences between the models, then apply the wilcoxon test to determine which models are significantly different\n",
    "if p_value < 0.05:\n",
    "  # Compute the pairwise differences between the models\n",
    "  pairwise_differences = np.apply_along_axis(lambda x: x - x[:, None], 1, performance_matrix)\n",
    "\n",
    "  # Compute the p-values for the pairwise differences using the Wilcoxon signed-rank test\n",
    "  p_values = np.apply_along_axis(lambda x: wilcoxon(x, zero_method=\"wilcox\")[1], 1, pairwise_differences)\n",
    "\n",
    "  # Compute the Bonferroni correction\n",
    "  bonferroni_correction = 0.05 / (p_values.shape[0] * (p_values.shape[0] - 1) / 2)\n",
    "\n",
    "  # Determine which models are significantly different\n",
    "  significant_differences = np.argwhere(p_values < bonferroni_correction)\n",
    "\n",
    "  # Print the significant differences\n",
    "  for difference in significant_differences:\n",
    "    print(f\"Model {difference[0]} is significantly different from model {difference[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
